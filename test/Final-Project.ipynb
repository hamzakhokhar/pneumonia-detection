{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification and Classification of Viral Pneumonia by Image-Based Deep Learning\n",
    "Hamza Khokhar\n",
    "Final Project\n",
    "Professor Biwas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.densenet import DenseNet121\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, BatchNormalization, Activation, GlobalAveragePooling2D, MaxPool2D\n",
    "from keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train PNEUMONIA: 3875\n",
      "Train NORMAL: 1341\n",
      "Test PNEUMONIA: 398\n",
      "Test PNEUMONIA: 242\n",
      "Total Number of Train samples: 5216\n",
      "Total Number of Test samples: 640\n"
     ]
    }
   ],
   "source": [
    "# getting all the paths from corresponding images\n",
    "paths_train_PNEUMONIA = glob.glob(\"chest_xray/train/PNEUMONIA/*.jpeg\")\n",
    "paths_train_NORMAL = glob.glob(\"chest_xray/train/NORMAL/*.jpeg\")\n",
    "paths_test_PNEUMONIA = glob.glob(\"chest_xray/test/PNEUMONIA/*.jpeg\")\n",
    "paths_test_NORMAL = glob.glob(\"chest_xray/test/NORMAL/*.jpeg\")\n",
    "\n",
    "\n",
    "# Total images for each folder\n",
    "print('Train PNEUMONIA: '+str(len(paths_train_PNEUMONIA)))\n",
    "print('Train NORMAL: '+str(len(paths_train_NORMAL)))\n",
    "print('Test PNEUMONIA: '+str(len(paths_test_PNEUMONIA)))\n",
    "print('Test PNEUMONIA: '+str(len(paths_test_NORMAL)))\n",
    "\n",
    "# Total images for each Directory\n",
    "print('Total Number of Train samples: '+ str(len(paths_train_PNEUMONIA)+len(paths_train_NORMAL)))\n",
    "print('Total Number of Test samples: '+ str(len(paths_test_PNEUMONIA)+len(paths_test_NORMAL)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a function to return a dataframe containing paths and labels for corresponding images  \n",
    "def create_dataframe(path_names,label_name):\n",
    "    paths = []\n",
    "    labels = []\n",
    "\n",
    "    for path in path_names:\n",
    "        paths.append(path)\n",
    "        labels.append(label_name)\n",
    "    df = pd.DataFrame()\n",
    "    df['paths'] = paths\n",
    "    df['labels'] = labels\n",
    "    return df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the create dataframe function twice in the pandas concat function to get our three main data frames for training and testing purposes\n",
    "train_df = pd.concat([\n",
    "    create_dataframe(paths_train_PNEUMONIA,'1'), \n",
    "    create_dataframe(paths_train_NORMAL,'0')\n",
    "],ignore_index=True)\n",
    "\n",
    "test_df = pd.concat([\n",
    "    create_dataframe(paths_test_PNEUMONIA,'1'), \n",
    "    create_dataframe(paths_test_NORMAL,'0')\n",
    "],ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chest_xray/train/PNEUMONIA/person63_bacteria_3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chest_xray/train/PNEUMONIA/person1438_bacteria...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chest_xray/train/PNEUMONIA/person755_bacteria_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chest_xray/train/PNEUMONIA/person478_virus_975...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chest_xray/train/PNEUMONIA/person661_bacteria_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>chest_xray/train/NORMAL/IM-0183-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5212</th>\n",
       "      <td>chest_xray/train/NORMAL/IM-0460-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>chest_xray/train/NORMAL/NORMAL2-IM-1011-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>chest_xray/train/NORMAL/NORMAL2-IM-0826-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>chest_xray/train/NORMAL/NORMAL2-IM-0960-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5216 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  paths labels\n",
       "0     chest_xray/train/PNEUMONIA/person63_bacteria_3...      1\n",
       "1     chest_xray/train/PNEUMONIA/person1438_bacteria...      1\n",
       "2     chest_xray/train/PNEUMONIA/person755_bacteria_...      1\n",
       "3     chest_xray/train/PNEUMONIA/person478_virus_975...      1\n",
       "4     chest_xray/train/PNEUMONIA/person661_bacteria_...      1\n",
       "...                                                 ...    ...\n",
       "5211          chest_xray/train/NORMAL/IM-0183-0001.jpeg      0\n",
       "5212          chest_xray/train/NORMAL/IM-0460-0001.jpeg      0\n",
       "5213  chest_xray/train/NORMAL/NORMAL2-IM-1011-0001.jpeg      0\n",
       "5214  chest_xray/train/NORMAL/NORMAL2-IM-0826-0001.jpeg      0\n",
       "5215  chest_xray/train/NORMAL/NORMAL2-IM-0960-0001.jpeg      0\n",
       "\n",
       "[5216 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the size and shape of the dataframes\n",
    "train_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chest_xray/test/PNEUMONIA/person147_bacteria_7...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chest_xray/test/PNEUMONIA/person100_bacteria_4...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chest_xray/test/PNEUMONIA/person78_bacteria_38...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chest_xray/test/PNEUMONIA/person124_bacteria_5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chest_xray/test/PNEUMONIA/person1647_virus_284...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>chest_xray/test/NORMAL/NORMAL2-IM-0309-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>chest_xray/test/NORMAL/NORMAL2-IM-0246-0001-00...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>chest_xray/test/NORMAL/NORMAL2-IM-0292-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>chest_xray/test/NORMAL/NORMAL2-IM-0221-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>chest_xray/test/NORMAL/NORMAL2-IM-0198-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 paths labels\n",
       "0    chest_xray/test/PNEUMONIA/person147_bacteria_7...      1\n",
       "1    chest_xray/test/PNEUMONIA/person100_bacteria_4...      1\n",
       "2    chest_xray/test/PNEUMONIA/person78_bacteria_38...      1\n",
       "3    chest_xray/test/PNEUMONIA/person124_bacteria_5...      1\n",
       "4    chest_xray/test/PNEUMONIA/person1647_virus_284...      1\n",
       "..                                                 ...    ...\n",
       "635   chest_xray/test/NORMAL/NORMAL2-IM-0309-0001.jpeg      0\n",
       "636  chest_xray/test/NORMAL/NORMAL2-IM-0246-0001-00...      0\n",
       "637   chest_xray/test/NORMAL/NORMAL2-IM-0292-0001.jpeg      0\n",
       "638   chest_xray/test/NORMAL/NORMAL2-IM-0221-0001.jpeg      0\n",
       "639   chest_xray/test/NORMAL/NORMAL2-IM-0198-0001.jpeg      0\n",
       "\n",
       "[640 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 validated image filenames belonging to 2 classes.\n",
      "Found 521 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,  \n",
    "        vertical_flip=True,\n",
    "        featurewise_center = False,\n",
    "        samplewise_center = False,\n",
    "        featurewise_std_normalization = False, \n",
    "        samplewise_std_normalization = False,\n",
    "        zca_whitening = False,\n",
    "        horizontal_flip = False,\n",
    "        #vertical_flip = False,\n",
    "        rotation_range = 10,  \n",
    "        zoom_range = 0.1, \n",
    "        width_shift_range = 0.1, \n",
    "        height_shift_range = 0.1)\n",
    "val_datagen=ImageDataGenerator(rescale = 1./255, \n",
    "    validation_split = 0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe= train_df,\n",
    "                                                  x_col= 'paths',\n",
    "                                                  y_col= 'labels',\n",
    "                                                  target_size=(200, 200),\n",
    "                                                  class_mode='binary',\n",
    "                                                  batch_size=32,\n",
    "                                                  shuffle=True,\n",
    "                                                  subset = 'training'\n",
    "                                                  )\n",
    " \n",
    "\n",
    "    \n",
    "validation_generator = val_datagen.flow_from_dataframe(dataframe= train_df,\n",
    "                                                  x_col= 'paths',\n",
    "                                                  y_col= 'labels',\n",
    "                                                  target_size=(200,200),\n",
    "                                                  class_mode= 'binary',\n",
    "                                                  batch_size= 32,\n",
    "                                                  shuffle=True,\n",
    "                                                  subset = 'validation'\n",
    "                                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 398/398 [00:02<00:00, 189.98it/s]\n",
      "100%|██████████| 242/242 [00:03<00:00, 64.22it/s]\n"
     ]
    }
   ],
   "source": [
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "for path in tqdm(paths_test_PNEUMONIA): \n",
    "    image= cv2.imread(path)\n",
    "    image=cv2.resize(image, (200, 200))\n",
    "    image=np.array(image)\n",
    "    image = image.astype('float32')\n",
    "    image /= 255 \n",
    "    test_images.append(image)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "for path in tqdm(paths_test_NORMAL): \n",
    "    image= cv2.imread(path)\n",
    "    image=cv2.resize(image, (200, 200))\n",
    "    image=np.array(image)\n",
    "    image = image.astype('float32')\n",
    "    image /= 255 \n",
    "    test_images.append(image)\n",
    "    test_labels.append(0)\n",
    "    \n",
    "test_images=np.array(test_images, np.float32)\n",
    "test_labels=np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 200, 200, 3)\n",
      "(640,)\n"
     ]
    }
   ],
   "source": [
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ \n",
    "    EarlyStopping(monitor = 'loss', patience = 7), \n",
    "    ReduceLROnPlateau(monitor = 'loss', patience = 4), \n",
    "    ModelCheckpoint('./model.best4.hdf5', monitor='loss' , save_best_only=True) # saving the best model\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Visulaizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(32,(3,3),input_shape = (300,300,3)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPooling2D())\n",
    "\n",
    "# model.add(Conv2D(32,(3,3)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPooling2D())\n",
    "\n",
    "# model.add(Conv2D(64,(3,3)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(MaxPooling2D())\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1024))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.4))\n",
    "# model.add(Dense(1)) # output\n",
    "# model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "# model.compile(loss = \"binary_crossentropy\",\n",
    "#               optimizer = \"rmsprop\",\n",
    "#               metrics = [\"accuracy\"])\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "        Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', input_shape = (200,200,3)),\n",
    "        Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPool2D(pool_size=(2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Flatten(),\n",
    "       \n",
    "        Dense(1024, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        \n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(1, activation = \"softmax\")\n",
    "        \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "163/163 [==============================] - 278s 2s/step - loss: 0.0000e+00 - accuracy: 0.7477 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 271s 2s/step - loss: 0.0000e+00 - accuracy: 0.7455 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      " 49/163 [========>.....................] - ETA: 3:04 - loss: 0.0000e+00 - accuracy: 0.7473"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(\n",
    "           train_generator, steps_per_epoch=train_generator.samples // 32, \n",
    "           epochs=100, validation_data=validation_generator, \n",
    "           validation_steps=validation_generator.samples // 32,callbacks = callbacks)\n",
    "\n",
    "\n",
    "\n",
    "# learning_history = model.fit_generator((train_gen), \n",
    "#                                epochs = 100, \n",
    "#                                steps_per_epoch = X_train.shape[0] // 32,\n",
    "#                                validation_data = (X_test, y_test),\n",
    "#                                callbacks = callbacks,\n",
    "#                         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5e8bb49715a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['accuracy', 'loss']):\n",
    "    ax[i].plot(hist.history[met])\n",
    "    ax[i].plot(hist.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONFUSION MATRIX ------------------\n",
      "[[103 139]\n",
      " [  1 397]]\n",
      "\n",
      "TEST METRICS ----------------------\n",
      "Accuracy: 78.125%\n",
      "Precision: 74.06716417910447%\n",
      "Recall: 99.74874371859298%\n",
      "F1-score: 85.01070663811562\n",
      "\n",
      "TRAIN METRIC ----------------------\n",
      "Train acc: 86.79\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "preds = model.predict(test_images)\n",
    "\n",
    "acc = accuracy_score(test_labels, np.round(preds))*100\n",
    "cm = confusion_matrix(test_labels, np.round(preds))\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print('CONFUSION MATRIX ------------------')\n",
    "print(cm)\n",
    "\n",
    "print('\\nTEST METRICS ----------------------')\n",
    "precision = tp/(tp+fp)*100\n",
    "recall = tp/(tp+fn)*100\n",
    "print('Accuracy: {}%'.format(acc))\n",
    "print('Precision: {}%'.format(precision))\n",
    "print('Recall: {}%'.format(recall))\n",
    "print('F1-score: {}'.format(2*precision*recall/(precision+recall)))\n",
    "\n",
    "print('\\nTRAIN METRIC ----------------------')\n",
    "print('Train acc: {}'.format(np.round((hist.history['accuracy'][-1])*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
