{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification and Classification of Viral Pneumonia by Image-Based Deep Learning\n",
    "Hamza Khokhar\n",
    "Final Project\n",
    "Professor Biwas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train PNEUMONIA: 3875\n",
      "Train NORMAL: 1341\n",
      "Test PNEUMONIA: 398\n",
      "Test PNEUMONIA: 242\n",
      "Val PNEUMONIA: 0\n",
      "Val Normal: 0\n",
      "Total Number of Train samples: 5216\n",
      "Total Number of Test samples: 640\n",
      "Total Number of Validation samples: 0\n"
     ]
    }
   ],
   "source": [
    "# getting all the paths from corresponding images\n",
    "paths_train_PNEUMONIA = glob.glob(\"chest_xray/train/PNEUMONIA/*.jpeg\")\n",
    "paths_train_NORMAL = glob.glob(\"chest_xray/train/NORMAL/*.jpeg\")\n",
    "paths_test_PNEUMONIA = glob.glob(\"chest_xray/test/PNEUMONIA/*.jpeg\")\n",
    "paths_test_NORMAL = glob.glob(\"chest_xray/test/NORMAL/*.jpeg\")\n",
    "paths_val_PNEUMONIA = glob.glob(\"chest_xray/val/NORMAL/*.jpeg\")\n",
    "paths_val_NORMAL = glob.glob(\"chest_xray/val/NORMAL/*.jpeg\")\n",
    "\n",
    "# Total images for each folder\n",
    "print('Train PNEUMONIA: '+str(len(paths_train_PNEUMONIA)))\n",
    "print('Train NORMAL: '+str(len(paths_train_NORMAL)))\n",
    "print('Test PNEUMONIA: '+str(len(paths_test_PNEUMONIA)))\n",
    "print('Test PNEUMONIA: '+str(len(paths_test_NORMAL)))\n",
    "print('Val PNEUMONIA: '+str(len(paths_val_PNEUMONIA)))\n",
    "print('Val Normal: '+str(len(paths_val_NORMAL)))\n",
    "\n",
    "# Total images for each Directory\n",
    "print('Total Number of Train samples: '+ str(len(paths_train_PNEUMONIA)+len(paths_train_NORMAL)))\n",
    "print('Total Number of Test samples: '+ str(len(paths_test_PNEUMONIA)+len(paths_test_NORMAL)))\n",
    "print('Total Number of Validation samples: '+ str(len(paths_val_PNEUMONIA)+len(paths_val_NORMAL)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3875/3875 [00:32<00:00, 120.12it/s]\n",
      "100%|██████████| 1341/1341 [00:29<00:00, 46.11it/s]\n",
      "100%|██████████| 398/398 [00:03<00:00, 132.58it/s]\n",
      "100%|██████████| 242/242 [00:04<00:00, 55.48it/s]\n"
     ]
    }
   ],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "\n",
    "for path in tqdm(paths_train_PNEUMONIA): \n",
    "    image= cv2.imread(path)\n",
    "    image=cv2.resize(image, (225, 225))\n",
    "    image=np.array(image)\n",
    "    image = image.astype('float32')\n",
    "    image /= 255 \n",
    "    train_images.append(image)\n",
    "    train_labels.append(1)\n",
    "\n",
    "for path in tqdm(paths_train_NORMAL): \n",
    "    image= cv2.imread(path)\n",
    "    image=cv2.resize(image, (225, 225))\n",
    "    image=np.array(image)\n",
    "    image = image.astype('float32')\n",
    "    image /= 255 \n",
    "    train_images.append(image)\n",
    "    train_labels.append(0)\n",
    "    \n",
    "for path in tqdm(paths_test_PNEUMONIA): \n",
    "    image= cv2.imread(path)\n",
    "    image=cv2.resize(image, (225, 225))\n",
    "    image=np.array(image)\n",
    "    image = image.astype('float32')\n",
    "    image /= 255 \n",
    "    test_images.append(image)\n",
    "    test_labels.append(1)\n",
    "    \n",
    "for path in tqdm(paths_test_NORMAL): \n",
    "    image= cv2.imread(path)\n",
    "    image=cv2.resize(image, (225, 225))\n",
    "    image=np.array(image)\n",
    "    image = image.astype('float32')\n",
    "    image /= 255 \n",
    "    test_images.append(image)\n",
    "    test_labels.append(0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_images=np.array(train_images, np.float32)\n",
    "train_labels=np.array(train_labels)\n",
    "test_images=np.array(test_images, np.float32)\n",
    "test_labels=np.array(test_labels)\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216, 225, 225, 3)\n",
      "(5216, 2)\n",
      "(640, 225, 225, 3)\n",
      "(640, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape) \n",
    "print(train_labels.shape) \n",
    "print(test_images.shape) \n",
    "print(test_labels.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center = False,\n",
    "        samplewise_center = False,\n",
    "        featurewise_std_normalization = False, \n",
    "        samplewise_std_normalization = False,\n",
    "        zca_whitening = False,\n",
    "        horizontal_flip = False,\n",
    "        vertical_flip = False,\n",
    "        rotation_range = 10,  \n",
    "        zoom_range = 0.1, \n",
    "        width_shift_range = 0.1, \n",
    "        height_shift_range = 0.1)\n",
    "\n",
    "datagen.fit(train_images)\n",
    "train_gen = datagen.flow(train_images, train_labels, batch_size = 32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(\n",
    "        weights=None,\n",
    "        include_top=False, \n",
    "        input_shape=(225,225,3)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(4096, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2,activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hamza/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 56/163 [=========>....................] - ETA: 20:41 - loss: 103.5263 - accuracy: 0.6979"
     ]
    }
   ],
   "source": [
    "learning_history = model.fit_generator((train_gen), \n",
    "                               epochs = 3, \n",
    "                               steps_per_epoch = train_images.shape[0] // 32,\n",
    "                               validation_data = (train_images, train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))\n",
    "ax = ax.ravel()\n",
    "\n",
    "for i, met in enumerate(['accuracy', 'loss']):\n",
    "    ax[i].plot(learning_history.history[met])\n",
    "    ax[i].plot(learning_history.history['val_' + met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    ax[i].legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
